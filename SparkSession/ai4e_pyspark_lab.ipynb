{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data using Spark Dataframe with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:06:53.655722Z",
     "start_time": "2024-04-01T06:06:53.651850Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# docker run --name pyspark_jupyter_notebook -it -p 8888:8888 -p 4040:4040 -i jupyter/pyspark-notebook:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:08.756103Z",
     "start_time": "2024-04-01T06:06:53.664729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Spark Version :3.5.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "import logging\n",
    "import sys\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.types import *\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime, date, timedelta\n",
    "import pytz\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.appName(\"mine\")\\\n",
    "    .config(\"spark.jars\", \"jar/postgresql-42.7.2.jar\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info('Spark Version :'+spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use movielens dataset for the following exercise\n",
    "https://grouplens.org/datasets/movielens/latest/\n",
    "\n",
    "1. Load movies.csv as movies dataframe. Cache the dataframe\n",
    "2. Load ratings.csv as ratings dataframe. Cache the dataframe\n",
    "3. Find the number of records in movies dataframe\n",
    "4. Find the number of records in ratings dataframe\n",
    "5. Validate the userId and movieId combination is unique\n",
    "6. Find average rating and count of rating per movieId using ratings dataframe\n",
    "7. Find top 10 movies based on the highest average ratings. Consider only those movies that have at least 100 ratings. Show movieId, title, average rating and rating count columns.\n",
    "8. Show temporary views for current Spark session\n",
    "9. Register movies dataframe and ratings dayaframe as movies and ratings temporary view respectively. Verify that you can see the new temporary views you just created.\n",
    "10. Using SQL statement, solve the problem statement for step #7. Match the results from step #7.\n",
    "11. Find average rating of each genre"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Load movies.csv as movies dataframe. Cache the dataframe\n",
    "### 3. Find the number of records in movies dataframe\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:14.536193Z",
     "start_time": "2024-04-01T06:07:08.757112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.option(\"header\", \"true\").csv(\"ml-latest-small/movies.csv\").cache()\n",
    "print(movies.count())\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Load ratings.csv as ratings dataframe. Cache the dataframe\n",
    "### 4. Find the number of records in ratings dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:15.312217Z",
     "start_time": "2024-04-01T06:07:14.537197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.option(\"header\", \"true\").csv(\"ml-latest-small/ratings.csv\").cache()\n",
    "print(ratings.count())\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Validate the userId and movieId combination is unique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:17.048861Z",
     "start_time": "2024-04-01T06:07:15.314224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "unique_count = ratings.groupBy(\"userId\", \"movieId\").count().filter(\"count > 1\").count()\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Find average rating and count of rating per movieId using ratings dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:18.351226Z",
     "start_time": "2024-04-01T06:07:17.049867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+\n",
      "|movieId|    average_rating|rating_count|\n",
      "+-------+------------------+------------+\n",
      "|    296| 4.197068403908795|         307|\n",
      "|   1090| 3.984126984126984|          63|\n",
      "| 115713|3.9107142857142856|          28|\n",
      "|   3210|3.4761904761904763|          42|\n",
      "|  88140|          3.546875|          32|\n",
      "|    829|2.6666666666666665|           9|\n",
      "|   2088|               2.5|          18|\n",
      "|   2294|3.2444444444444445|          45|\n",
      "|   4821|               3.1|           5|\n",
      "|  48738|             3.975|          20|\n",
      "|   3959|             3.625|           8|\n",
      "|  89864|3.6315789473684212|          19|\n",
      "|   2136|2.4642857142857144|          14|\n",
      "|    691|3.3333333333333335|           3|\n",
      "|   3606|              3.75|           4|\n",
      "| 121007|               4.0|           1|\n",
      "|   6731|             3.625|           8|\n",
      "|  27317|              3.75|           6|\n",
      "|  26082|               4.5|           3|\n",
      "| 100553|               4.5|           2|\n",
      "+-------+------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "average_rating = ratings.groupBy(\"movieId\").agg(F.avg(\"rating\").alias(\"average_rating\") , F.count(\"rating\").alias(\"rating_count\"))\n",
    "average_rating.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:18.663154Z",
     "start_time": "2024-04-01T06:07:18.352236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-------+------+---------+\n",
      "|movieId|               title|              genres|userId|movieId|rating|timestamp|\n",
      "+-------+--------------------+--------------------+------+-------+------+---------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|     1|      1|   4.0|964982703|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|     1|      3|   4.0|964981247|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|     1|      6|   4.0|964982224|\n",
      "|     47|Seven (a.k.a. Se7...|    Mystery|Thriller|     1|     47|   5.0|964983815|\n",
      "|     50|Usual Suspects, T...|Crime|Mystery|Thr...|     1|     50|   5.0|964982931|\n",
      "|     70|From Dusk Till Da...|Action|Comedy|Hor...|     1|     70|   3.0|964982400|\n",
      "|    101|Bottle Rocket (1996)|Adventure|Comedy|...|     1|    101|   5.0|964980868|\n",
      "|    110|   Braveheart (1995)|    Action|Drama|War|     1|    110|   4.0|964982176|\n",
      "|    151|      Rob Roy (1995)|Action|Drama|Roma...|     1|    151|   5.0|964984041|\n",
      "|    157|Canadian Bacon (1...|          Comedy|War|     1|    157|   5.0|964984100|\n",
      "|    163|    Desperado (1995)|Action|Romance|We...|     1|    163|   5.0|964983650|\n",
      "|    216|Billy Madison (1995)|              Comedy|     1|    216|   5.0|964981208|\n",
      "|    223|       Clerks (1994)|              Comedy|     1|    223|   3.0|964980985|\n",
      "|    231|Dumb & Dumber (Du...|    Adventure|Comedy|     1|    231|   5.0|964981179|\n",
      "|    235|      Ed Wood (1994)|        Comedy|Drama|     1|    235|   4.0|964980908|\n",
      "|    260|Star Wars: Episod...|Action|Adventure|...|     1|    260|   5.0|964981680|\n",
      "|    296| Pulp Fiction (1994)|Comedy|Crime|Dram...|     1|    296|   3.0|964982967|\n",
      "|    316|     Stargate (1994)|Action|Adventure|...|     1|    316|   3.0|964982310|\n",
      "|    333|    Tommy Boy (1995)|              Comedy|     1|    333|   5.0|964981179|\n",
      "|    349|Clear and Present...|Action|Crime|Dram...|     1|    349|   4.0|964982563|\n",
      "+-------+--------------------+--------------------+------+-------+------+---------+\n"
     ]
    }
   ],
   "source": [
    "tmp = movies.join(ratings, movies[\"movieId\"] == ratings[\"movieId\"], \"inner\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Find top 10 movies based on the highest average ratings. Consider only those movies that have at least 100 ratings. Show movieId, title, average rating and rating count columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:19.756826Z",
     "start_time": "2024-04-01T06:07:18.664159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------+\n",
      "|               title|   average_rating|rating_count|\n",
      "+--------------------+-----------------+------------+\n",
      "|Shawshank Redempt...|4.429022082018927|         317|\n",
      "|Godfather, The (1...|        4.2890625|         192|\n",
      "|   Fight Club (1999)|4.272935779816514|         218|\n",
      "|Godfather: Part I...| 4.25968992248062|         129|\n",
      "|Departed, The (2006)|4.252336448598131|         107|\n",
      "|   Goodfellas (1990)|             4.25|         126|\n",
      "|Dark Knight, The ...|4.238255033557047|         149|\n",
      "|Usual Suspects, T...|4.237745098039215|         204|\n",
      "|Princess Bride, T...|4.232394366197183|         142|\n",
      "|Star Wars: Episod...|4.231075697211155|         251|\n",
      "+--------------------+-----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "movies_10 = average_rating.join(movies, average_rating[\"movieId\"]==movies[\"movieId\"], \"inner\").select(\"title\", \"average_rating\", \"rating_count\").filter(F.col(\"rating_count\") > 100).orderBy(F.desc(\"average_rating\")).limit(10)\n",
    "movies_10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Show temporary views for current Spark session"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:23.663739Z",
     "start_time": "2024-04-01T06:07:19.757833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Table(name='payment_transaction', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## localhost:4040\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Register movies dataframe and ratings dataframe as movies and ratings temporary view respectively. Verify that you can see the new temporary views you just created."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:23.855203Z",
     "start_time": "2024-04-01T06:07:23.664748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Table(name='payment_transaction', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False),\n Table(name='average_rating', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n Table(name='movies', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n Table(name='ratings', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.createOrReplaceTempView(\"movies\")\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "average_rating.createOrReplaceTempView(\"average_rating\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10. Using SQL statement, solve the problem statement for step #7. Match the results from step #7."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------+\n",
      "|               title|   average_rating|rating_count|\n",
      "+--------------------+-----------------+------------+\n",
      "|Shawshank Redempt...|4.429022082018927|         317|\n",
      "|Godfather, The (1...|        4.2890625|         192|\n",
      "|   Fight Club (1999)|4.272935779816514|         218|\n",
      "|Godfather: Part I...| 4.25968992248062|         129|\n",
      "|Departed, The (2006)|4.252336448598131|         107|\n",
      "|   Goodfellas (1990)|             4.25|         126|\n",
      "|Dark Knight, The ...|4.238255033557047|         149|\n",
      "|Usual Suspects, T...|4.237745098039215|         204|\n",
      "|Princess Bride, T...|4.232394366197183|         142|\n",
      "|Star Wars: Episod...|4.231075697211155|         251|\n",
      "+--------------------+-----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "movies_10_sql = spark.sql(\"SELECT m.title, a.average_rating, a.rating_count FROM average_rating a JOIN movies m ON a.movieId = m.movieId WHERE a.rating_count > 100 ORDER BY a.average_rating DESC LIMIT 10\")\n",
    "movies_10_sql.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:24.730688Z",
     "start_time": "2024-04-01T06:07:23.859210Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 11. Find average rating of each genre"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+---------+\n",
      "|movieId|               title|              genres|    genre|\n",
      "+-------+--------------------+--------------------+---------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|Adventure|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|Animation|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...| Children|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   Comedy|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|  Fantasy|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|Adventure|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...| Children|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|  Fantasy|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   Comedy|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|  Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|   Comedy|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|    Drama|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|  Romance|\n",
      "|      5|Father of the Bri...|              Comedy|   Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|   Action|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|    Crime|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...| Thriller|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|   Comedy|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|  Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|Adventure|\n",
      "+-------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "movies_genre = movies.withColumn(\"genre\", F.explode(F.split(\"genres\", \"\\|\")))\n",
    "movies_genre.show()\n",
    "movies_genre.createOrReplaceTempView(\"movies_genre\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:24.826207Z",
     "start_time": "2024-04-01T06:07:24.731695Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|             genre|    average_rating|\n",
      "+------------------+------------------+\n",
      "|             Crime| 3.658293867274144|\n",
      "|           Romance|3.5065107040388437|\n",
      "|          Thriller|3.4937055799183425|\n",
      "|         Adventure|3.5086089151939075|\n",
      "|             Drama|3.6561844113718758|\n",
      "|               War|   3.8082938876312|\n",
      "|       Documentary| 3.797785069729286|\n",
      "|           Fantasy|3.4910005070136894|\n",
      "|           Mystery| 3.632460255407871|\n",
      "|           Musical|3.5636781053649105|\n",
      "|         Animation|3.6299370349170004|\n",
      "|         Film-Noir| 3.920114942528736|\n",
      "|(no genres listed)|3.4893617021276597|\n",
      "|              IMAX| 3.618335343787696|\n",
      "|            Horror| 3.258195034974626|\n",
      "|           Western| 3.583937823834197|\n",
      "|            Comedy|3.3847207640898267|\n",
      "|          Children| 3.412956125108601|\n",
      "|            Action| 3.447984331646809|\n",
      "|            Sci-Fi| 3.455721162210752|\n",
      "+------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "average_rating_genre = spark.sql(\"SELECT genre, AVG(rating) AS average_rating FROM movies_genre mg JOIN ratings r ON mg.movieId = r.movieId GROUP BY genre\")\n",
    "average_rating_genre.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:25.525346Z",
     "start_time": "2024-04-01T06:07:24.826727Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Read data from jdbc + hive table\n",
    "\n",
    "1. Create 3 dataframe - payment_transaction, account, customer in Spark based on payment_transaction table in demo_test\n",
    "2. Save payment_transaction, account, customer as parquet file in HDFS\n",
    "3. Save the payment_transaction dataframe as hive table. Verify that payment_transaction table is accessible in hive as well.\n",
    "4. Delete the payment_transaction table from hive."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Create 3 dataframe - payment_transaction, account, customer in Spark based on payment_transaction table in demo_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://introduction-01-intro-ap-southeast-1-dev-introduction-db.cpfm8ml2cxp2.ap-southeast-1.rds.amazonaws.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"ai4e_test.payment_transaction\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres123\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "account = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://introduction-01-intro-ap-southeast-1-dev-introduction-db.cpfm8ml2cxp2.ap-southeast-1.rds.amazonaws.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"ai4e_test.account\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres123\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "customer = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://introduction-01-intro-ap-southeast-1-dev-introduction-db.cpfm8ml2cxp2.ap-southeast-1.rds.amazonaws.com:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"ai4e_test.customer\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres123\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:29.104146Z",
     "start_time": "2024-04-01T06:07:25.526853Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Save payment_transaction, account, customer as parquet file in HDFS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction.write.mode(\"overwrite\").parquet(\"payment_transaction.parquet\")\n",
    "account.write.mode(\"overwrite\").parquet(\"account.parquet\")\n",
    "customer.write.mode(\"overwrite\").parquet(\"customer.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:07:36.662604Z",
     "start_time": "2024-04-01T06:07:29.105182Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Save the payment_transaction dataframe as hive table. Verify that payment_transaction table is accessible in hive as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------+-------------+-------------------+------------+\n",
      "|            trans_id|              acc_id|before_balance|amount|after_balance|   transaction_time|payment_code|\n",
      "+--------------------+--------------------+--------------+------+-------------+-------------------+------------+\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165554|  -974|       164580|2023-08-01 02:20:00|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164580|  -242|       164338|2023-08-01 04:35:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164338|   459|       164797|2023-08-01 07:39:00|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164797|   753|       165550|2023-08-01 11:03:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165550|  -736|       164814|2023-08-01 13:12:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164814|   354|       165168|2023-08-02 02:05:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165168|   -78|       165090|2023-08-03 04:01:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165090|  -786|       164304|2023-08-03 07:12:00|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        107483|   978|       108461|2023-08-01 03:15:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108461|   479|       108940|2023-08-01 07:20:00|           5|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108940|   184|       109124|2023-08-01 09:23:00|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        109124|  -168|       108956|2023-08-01 11:27:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108956|   -84|       108872|2023-08-01 14:36:00|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108872|    -9|       108863|2023-08-02 04:10:00|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108863|    43|       108906|2023-08-02 06:34:00|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108906|  -680|       108226|2023-08-03 02:24:00|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108226|  -521|       107705|2023-08-03 05:52:00|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194441|  -412|       194029|2023-08-01 03:12:00|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194029|    81|       194110|2023-08-02 02:14:00|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194110|  -849|       193261|2023-08-03 04:18:00|           2|\n",
      "+--------------------+--------------------+--------------+------+-------------+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "payment_transaction.write.mode(\"overwrite\").saveAsTable(\"payment_transaction\")\n",
    "spark.sql(\"SELECT * FROM payment_transaction\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:12:55.471451Z",
     "start_time": "2024-04-01T06:12:52.346148Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Delete the payment_transaction table from hive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE payment_transaction\")\n",
    "# spark.sql(\"SELECT * FROM payment_transaction\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:13:08.488102Z",
     "start_time": "2024-04-01T06:13:08.484765Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 3: Data partitioning\n",
    "\n",
    "1. Create a dataframe in Spark that refers to Hive table payment_transaction.\n",
    "2. Find total number of rows. \n",
    "3. Parse the time column as date time\n",
    "4. Save the payment_transaction data with partitioned by year and month based on the time field that you parsed\n",
    "5. Reload the partitioned dataset and verify the number of record maches with the original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Create a dataframe in Spark that refers to Hive table payment_transaction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction = spark.read.table(\"payment_transaction\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:13:35.908602Z",
     "start_time": "2024-04-01T06:13:35.886734Z"
    }
   },
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Find total number of rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100387\n"
     ]
    }
   ],
   "source": [
    "print(payment_transaction.count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:13:37.979569Z",
     "start_time": "2024-04-01T06:13:37.900469Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Parse the time column as date time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------+-------------+----------------+------------+\n",
      "|            trans_id|              acc_id|before_balance|amount|after_balance|transaction_time|payment_code|\n",
      "+--------------------+--------------------+--------------+------+-------------+----------------+------------+\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165554|  -974|       164580|      2023-08-01|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164580|  -242|       164338|      2023-08-01|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164338|   459|       164797|      2023-08-01|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164797|   753|       165550|      2023-08-01|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165550|  -736|       164814|      2023-08-01|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164814|   354|       165168|      2023-08-02|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165168|   -78|       165090|      2023-08-03|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165090|  -786|       164304|      2023-08-03|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        107483|   978|       108461|      2023-08-01|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108461|   479|       108940|      2023-08-01|           5|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108940|   184|       109124|      2023-08-01|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        109124|  -168|       108956|      2023-08-01|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108956|   -84|       108872|      2023-08-01|           1|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108872|    -9|       108863|      2023-08-02|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108863|    43|       108906|      2023-08-02|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108906|  -680|       108226|      2023-08-03|           2|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108226|  -521|       107705|      2023-08-03|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194441|  -412|       194029|      2023-08-01|           3|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194029|    81|       194110|      2023-08-02|           4|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194110|  -849|       193261|      2023-08-03|           2|\n",
      "+--------------------+--------------------+--------------+------+-------------+----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "payment_transaction = payment_transaction.withColumn(\"transaction_time\", F.to_date(\"transaction_time\", \"yyyy-MM-dd\"))\n",
    "payment_transaction.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:16:06.233625Z",
     "start_time": "2024-04-01T06:16:06.137275Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Save the payment_transaction data with partitioned by year and month based on the time field that you parsed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction.write.partitionBy(\"transaction_time\").mode(\"overwrite\").parquet(\"payment_transaction_partitioned.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:17:25.214138Z",
     "start_time": "2024-04-01T06:17:24.545959Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Reload the partitioned dataset and verify the number of record matches with the original."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------+-------------+------------+----------------+\n",
      "|            trans_id|              acc_id|before_balance|amount|after_balance|payment_code|transaction_time|\n",
      "+--------------------+--------------------+--------------+------+-------------+------------+----------------+\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165554|  -974|       164580|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164580|  -242|       164338|           2|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164338|   459|       164797|           1|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        164797|   753|       165550|           2|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        165550|  -736|       164814|           2|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        107483|   978|       108461|           2|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108461|   479|       108940|           5|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108940|   184|       109124|           1|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        109124|  -168|       108956|           2|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        108956|   -84|       108872|           1|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        194441|  -412|       194029|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        157101|   800|       157901|           4|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        157901|  -917|       156984|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        156984|  -581|       156403|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        156403|   433|       156836|           5|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        168414|   661|       169075|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        169075|   836|       169911|           4|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        169911|   734|       170645|           4|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        170645|   114|       170759|           3|      2023-08-01|\n",
      "|c3fedcdb7c388930d...|7858bc9db331ac3e3...|        170759|  -789|       169970|           4|      2023-08-01|\n",
      "+--------------------+--------------------+--------------+------+-------------+------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "payment_transaction_partitioned = spark.read.parquet(\"payment_transaction_partitioned.parquet\")\n",
    "payment_transaction_partitioned.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:17:45.218147Z",
     "start_time": "2024-04-01T06:17:45.060453Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Data format\n",
    "\n",
    "Save payment_transaction.csv dataset in the following formats and compare the size on disk\n",
    "\n",
    "1. csv \n",
    "2. Json\n",
    "3. Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CSV file format: ? MB\n",
    " - CSV gzip compressed: ? MB\n",
    " - Json uncompressed: ? MB\n",
    " - Parquet snappy compressed: ? MB"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction.write.mode(\"overwrite\").csv(\"payment_transaction.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:17:53.104505Z",
     "start_time": "2024-04-01T06:17:52.713415Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'du' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!du -sh payment_transaction.csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:09.034181Z",
     "start_time": "2024-04-01T06:18:09.017017Z"
    }
   },
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gzip payment_transaction.csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:13.699764Z",
     "start_time": "2024-04-01T06:18:13.681630Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction.write.mode(\"overwrite\").json(\"payment_transaction.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:14.679645Z",
     "start_time": "2024-04-01T06:18:14.253678Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'du' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!du -sh payment_transaction.json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:14.785419Z",
     "start_time": "2024-04-01T06:18:14.766647Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "payment_transaction.write.mode(\"overwrite\").parquet(\"payment_transaction.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:15.558994Z",
     "start_time": "2024-04-01T06:18:15.344147Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'du' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!du -sh payment_transaction.parquet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T06:18:16.436496Z",
     "start_time": "2024-04-01T06:18:16.417669Z"
    }
   },
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
